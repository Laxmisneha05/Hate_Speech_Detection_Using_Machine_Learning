{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dt3HvP7akhTA"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KusC0DnAH2tw",
        "outputId": "32dcaa4a-1806-4ec7-927f-7a65cb421ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Download stopwords and punkt (for word tokenization)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k2wvZcmH3_5",
        "outputId": "d13a6fb1-ddde-4793-968b-43c40ea837f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "5           5      3            1                   2        0      1   \n",
            "6           6      3            0                   3        0      1   \n",
            "7           7      3            0                   3        0      1   \n",
            "8           8      3            0                   3        0      1   \n",
            "9           9      3            1                   2        0      1   \n",
            "\n",
            "                                               tweet  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
            "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
            "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
            "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
            "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
            "9  \" @rhythmixx_ :hobbies include: fighting Maria...  \n"
          ]
        }
      ],
      "source": [
        "# loading the dataset\n",
        "\n",
        "df = pd.read_csv('twitter.csv')\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67no-rITH6DT",
        "outputId": "0af47e8b-2194-48ec-d171-7edb68f1d5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "5           5      3            1                   2        0      1   \n",
            "6           6      3            0                   3        0      1   \n",
            "7           7      3            0                   3        0      1   \n",
            "8           8      3            0                   3        0      1   \n",
            "9           9      3            1                   2        0      1   \n",
            "\n",
            "                                               tweet              labels  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...              Normal  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  Offensive Language  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  Offensive Language  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  Offensive Language  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  Offensive Language  \n",
            "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  Offensive Language  \n",
            "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  Offensive Language  \n",
            "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  Offensive Language  \n",
            "8  \" &amp; you might not get ya bitch back &amp; ...  Offensive Language  \n",
            "9  \" @rhythmixx_ :hobbies include: fighting Maria...  Offensive Language  \n"
          ]
        }
      ],
      "source": [
        "df['labels'] = df['class'].map({0: 'Hate Speech', 1: 'Offensive Language', 2: 'Normal'})\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPLnStkwH-vo",
        "outputId": "c8afde24-7492-4976-c7a9-525b72877f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet              labels\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...              Normal\n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  Offensive Language\n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  Offensive Language\n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  Offensive Language\n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  Offensive Language\n"
          ]
        }
      ],
      "source": [
        "#splitting the columns\n",
        "df = df[['tweet', 'labels']]\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MV_Ap9FgIA17"
      },
      "outputs": [],
      "source": [
        "# cleaning the text\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopwords]\n",
        "    text = ' '.join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F2mQsZTBIGxT"
      },
      "outputs": [],
      "source": [
        "# split data into train, validation, and test sets\n",
        "X = np.array(df['tweet'])\n",
        "y = np.array(df['labels'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ftntPQAIIlr"
      },
      "outputs": [],
      "source": [
        "# Vectorize text data\n",
        "cv = CountVectorizer()\n",
        "X_train = cv.fit_transform(X_train)\n",
        "X_val = cv.transform(X_val)\n",
        "X_test = cv.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "849xqXN8SA1V"
      },
      "source": [
        "# **Model 1 : Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh-04-xHKa2F",
        "outputId": "7c2bdc7a-9a9a-4099-96ac-482205a714ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
            "Best Parameters:  {'criterion': 'gini', 'max_depth': 50, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "Best F1 Score:  0.8793256680285086\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.55      0.12      0.19       465\n",
            "            Normal       0.75      0.94      0.83      1379\n",
            "Offensive Language       0.94      0.94      0.94      6335\n",
            "\n",
            "          accuracy                           0.89      8179\n",
            "         macro avg       0.75      0.66      0.65      8179\n",
            "      weighted avg       0.88      0.89      0.88      8179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5, 10],\n",
        "    'max_features': [None, 'sqrt', 'log2'],  # Use None instead of 'auto'\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(estimator=dt_model,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='f1_weighted',  # You can also use 'accuracy', 'precision', 'recall', etc.\n",
        "                           cv=5,  # Number of cross-validation folds\n",
        "                           verbose=1,\n",
        "                           n_jobs=-1)  # Use all available cores\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best F1 Score: \", grid_search.best_score_)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X5GmucxDIOYb"
      },
      "outputs": [],
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhYPiD76IlZ5",
        "outputId": "e7dcb5fb-6676-4977-abfc-038b6576864f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERBl5upRIl9u",
        "outputId": "e11f219a-af23-4b36-ccac-4bb2a4e49453"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['decision_tree_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(best_model, 'decision_tree_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzvZk_Q-Iq25",
        "outputId": "6e509da4-b54f-49be-ac31-ea1c6be29a7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_count_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Assuming df['tweet'] has already been cleaned and preprocessed\n",
        "\n",
        "# Split data\n",
        "X = np.array(df['tweet'])\n",
        "y = np.array(df['labels'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Use TF-IDF with unigrams and bigrams\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_val = tfidf.transform(X_val)\n",
        "X_test = tfidf.transform(X_test)\n",
        "\n",
        "\n",
        "# Save the vectorizer for later use\n",
        "joblib.dump(cv, 'tfidf_count_vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ZdvDmRBCvA"
      },
      "source": [
        "# **Model 2 : Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p9xuR9tKX6q",
        "outputId": "104a0725-f48c-4a64-f932-d518cd88c79f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logistic_regression_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the model with Logistic Regression\n",
        "clf = LogisticRegression(max_iter=200)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the Logistic Regression model\n",
        "joblib.dump(clf, 'logistic_regression_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOknC-8VMlcu",
        "outputId": "d72dd61d-764a-494b-853c-3f2e77c5894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.61      0.21      0.31       288\n",
            "Offensive Language       0.88      0.74      0.81       814\n",
            "            Normal       0.90      0.97      0.94      3855\n",
            "\n",
            "          accuracy                           0.89      4957\n",
            "         macro avg       0.80      0.64      0.69      4957\n",
            "      weighted avg       0.88      0.89      0.88      4957\n",
            "\n",
            "Test Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.57      0.18      0.27       290\n",
            "Offensive Language       0.86      0.73      0.79       835\n",
            "            Normal       0.89      0.97      0.93      3832\n",
            "\n",
            "          accuracy                           0.88      4957\n",
            "         macro avg       0.77      0.63      0.66      4957\n",
            "      weighted avg       0.87      0.88      0.87      4957\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Test Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEPcZCn3BIiM"
      },
      "source": [
        "# **Model 3 : Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BiEORo_OxCL",
        "outputId": "a691601f-4100-4f11-b9e1-457e2b642cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train the model\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(clf, 'random_forest_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyPlR93EOxbs",
        "outputId": "1045d627-09b0-4752-e2b8-78b79641b5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.60      0.17      0.26       288\n",
            "Offensive Language       0.86      0.77      0.82       814\n",
            "            Normal       0.90      0.97      0.93      3855\n",
            "\n",
            "          accuracy                           0.89      4957\n",
            "         macro avg       0.79      0.64      0.67      4957\n",
            "      weighted avg       0.88      0.89      0.88      4957\n",
            "\n",
            "Test Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.54      0.17      0.26       290\n",
            "Offensive Language       0.83      0.76      0.79       835\n",
            "            Normal       0.90      0.96      0.93      3832\n",
            "\n",
            "          accuracy                           0.88      4957\n",
            "         macro avg       0.76      0.63      0.66      4957\n",
            "      weighted avg       0.87      0.88      0.87      4957\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Test Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUmwfB-jBNgV"
      },
      "source": [
        "# **Model 4 : Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAS1ybKWPEKE",
        "outputId": "d9e78e2a-fd5b-44ce-a7e3-e96117f924c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['naive_bayes_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Train the model\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(clf, 'naive_bayes_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO_Y0vESPQ2Z",
        "outputId": "c987bb5f-45ff-4a01-8517-7481f7758e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.00      0.00      0.00       288\n",
            "Offensive Language       0.98      0.07      0.13       814\n",
            "            Normal       0.79      1.00      0.88      3855\n",
            "\n",
            "          accuracy                           0.79      4957\n",
            "         macro avg       0.59      0.36      0.34      4957\n",
            "      weighted avg       0.77      0.79      0.71      4957\n",
            "\n",
            "Test Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.00      0.00      0.00       290\n",
            "Offensive Language       1.00      0.06      0.12       835\n",
            "            Normal       0.78      1.00      0.88      3832\n",
            "\n",
            "          accuracy                           0.78      4957\n",
            "         macro avg       0.59      0.35      0.33      4957\n",
            "      weighted avg       0.77      0.78      0.70      4957\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Test Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e01ilfqBTnC"
      },
      "source": [
        "# **Model 5 : KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWtvTq41PUXQ",
        "outputId": "f7903913-6b6c-425d-c6c3-13a0bde49d58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knn_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Train the model\n",
        "clf = KNeighborsClassifier(n_neighbors=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(clf, 'knn_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9XFTZoPUPZ",
        "outputId": "64f79e96-18af-403e-8cfe-e72ceb757e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.31      0.32      0.31       288\n",
            "Offensive Language       0.18      0.96      0.30       814\n",
            "            Normal       0.93      0.08      0.16      3855\n",
            "\n",
            "          accuracy                           0.24      4957\n",
            "         macro avg       0.47      0.45      0.26      4957\n",
            "      weighted avg       0.77      0.24      0.19      4957\n",
            "\n",
            "Test Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       Hate Speech       0.33      0.36      0.34       290\n",
            "Offensive Language       0.18      0.94      0.31       835\n",
            "            Normal       0.94      0.09      0.17      3832\n",
            "\n",
            "          accuracy                           0.25      4957\n",
            "         macro avg       0.49      0.46      0.27      4957\n",
            "      weighted avg       0.78      0.25      0.20      4957\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Test Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Hate Speech', 'Offensive Language', 'Normal']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}